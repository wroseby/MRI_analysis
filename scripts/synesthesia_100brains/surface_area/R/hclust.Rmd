---
title: "Hierarchical clustering of HCP parcels"
output:
  pdf_document: default

params:
  seed: 91939
---
## Absolute surface area
**Prerequisites:** surface area data for 360 HCP parcels in .csv format with metadata in columns 1 through 8.  

This is a notebook to perform hierarchical clustering of partial correlations between HCP parcels. The purpose of this approach is to reduce the number of nodes to below 100 so we can use partial correlations to form networks for a synesthete sample of n = 102 participants. In general, clustering will be performed on partial correlations of left-right averaged data from the control sample of n = 650 participants. However, we will run diagnostics on the clusters, including examining consistency between multiple resamples of n = 300 controls. Partial correlations will be clustered using Euclidean distance as a measure of distance between parcels:

$$ d(p,q) =  \sqrt{\sum_{i=1}^{n}{(q_i-p_i)^2}}$$
Once an optimal clustering is found via diagnostic measures, we will summarise the results within clusters and export the results for network analysis with python. We will then report the results of this and other analysis in this notebook so that everything is in one place.

```{r load_packages, include=F}
# Load packages #

library(ppcor)
library(dendextend)
library(dplyr)
library(viridis)
library(ggplot2)
library(reshape2)
library(mclust)
library(cluster)
library(clValid)
library(MatchIt)
library(gridExtra)
library(copula)
library(effsize)
library(MASS)
library(mgcv)
library(MVN)
library(effectsize)
library(gratia)
```

```{r load_data, include=F}
# Read in data, functions, and set paths for saving #

datapath =  'D:/Documents/Academia/projects/ward_lab/MRI_analysis/datasets/synesthesia_100brains/'
savepath_data = 'D:/Documents/Academia/projects/ward_lab/MRI_analysis/shared/synesthesia_100brains/surface_area/'
savepath_outputs = 'D:/Documents/Academia/projects/ward_lab/MRI_analysis/outputs/synesthesia_100brains/surface_area/R/'
source("D:/Documents/Academia/projects/ward_lab/MRI_analysis/scripts/common/R_custom_functions.R") 
SA_abs = read.csv(paste0(datapath, '/surface_area/biomarker_S1C_harm.csv'), row.names = 1)
SA_rel = read.csv(paste0(datapath, '/surface_area/biomarker_S1A_harm.csv'), row.names = 1)
parcel_positions = read.csv(paste0(datapath, '/common/parcel_positions_flat.csv'))
```

```{r set_parameters, include=F}
# Set parameters to be used throughout notebook --- change for customisation #

# Set data to be used
data = SA_abs  # primary data
data_lr = lr_average(data)  # left-right averaged data

# Set group structure
exp_group = 'Syn'  # name of experimental group
sample_n = 102  # number of observations per group

# Set indexes for data vs metadata columns
data_cols = 8:ncol(data)  # columns with data
data_cols_lr = 8:ncol(data_lr)  # columns with lr-averaged data
metadata_cols = 1:7  # columns with metadata

# Set paths to data and save locations
project_path = 'D:/Documents/Academia/projects/ward_lab/MRI_analysis/'  # path to main project folder
datapath = paste0(project_path, 'datasets/synesthesia_100brains/')  # path to primary data
savepath_data = paste0(project_path, 'shared/synesthesia_100brains/surface_area/')  # path to save data 
savepath_outputs = paste0(project_path, 'outputs/synesthesia_100brains/surface_area/R/')  # path to save figures etc.
python_imports = 'D:/Documents/Academia/projects/ward_lab/MRI_analysis/outputs/synesthesia_100brains/surface_area/python/'  # outputs from python
```

# Initial checks

Prior to beginning the clustering procedure, we need to check that all assumptions of our intended approach are met. 


## Data normality

Ultimately, we are interested in using partial correlations to form networks that accurately describe the structural relationships between a set of regions of the brain. However, this description is only fully accurate under a gaussian assumption; i.e.: partial correlations will only capture the full dependence structure of the data if it follows a multivariate normal distribution. Since we will be carrying out clustering on partial correlations observed in control data, we want to see if the data follows a multivariate normal distribution, and so is well described by the partial correlations in the first instance. To test this, we will implement a series of tests for multivariate normality.


```{r lr_MVN_tests}
# MVN tests for lr-averaged control data #

MVN_test(data_lr[data_lr$Group == 'Control', data_cols_lr])
```

While the tests are not in complete agreement of an MVN distribution, the Mahalanobis distance plot indicates that an MVN assumption is not inappropriate. The results here are likely affected by both the large number of dimensions (n = 180) and the large number of samples for each dimension (n = 650). This means it is easier for the data to fail normality tests. We can check the univariate normality to see how many individual variables differ from normality.

```{r univariate_normality}
# Per-parcel normality tests #

table(mvn(data_lr[, -metadata_cols])
      [['univariateNormality']]$Normality)
```

Indeed, we see that while most (92%) of the per-parcel data are normally distributed, only a small number are not. Therefore, we can assume multivariate normality and that partial correlations will capture the majority of the dependence structure of the data.


## Group differences in parcel morphology

One other concern is whether there are group differences in the features of some parcels. While additive differences don't affect correlation structure, if there is a multiplicative difference in a parcel feature between groups, this could result in a correlational difference with other parcels. This then would be a trivial finding, since it wouldn't reflect regional co-growth, but rather a difference in a single region's growth pattern. To test for this, we can carry out F-tests of variance for each parcel. Since it would also be interesting to see average parcel surface areas differ between groups, we can also fit linear models to compare means.

```{r group_parcel_variance}
# Compare parcel variances and means between groups #

# Run F-tests for variance
test_summaries = list()  
for (region in colnames(data_lr[, data_cols_lr])) { 
  res = var.test(data_lr[[region]][data_lr$Group == 'Control'], 
                 data_lr[[region]][data_lr$Group == exp_group])  
  test_summaries[[region]] = res
}
sig_results = lapply(test_summaries, function(x) x$p.value[x$p.value < 0.05])
print(sig_results[sapply(sig_results, length) > 0])

# Fit linear model for each area
model_summaries = list()
for (region in colnames(data_lr[, data_cols_lr])) { 
  model = lm(data_lr[[region]] ~ Group, data = data_lr)  
  model_summaries[[region]] = summary(model)
}
p_vals = sapply(model_summaries, FUN = function(list){ 
  list[["coefficients"]][2,4] 
})
print(p_vals[p_vals < 0.05])
```

For variance, only 5 (2.8%) of parcels show a group difference. This is below 5% as so these would likely not show differences under multiple comparison correction. For the means, 62 (34.4%) of parcels do show a difference in means. While this won't affect the magnitude of pearson correlations, it is worth noting for future analysis. 



# Hierarchical clustering optimisation

Now that we have validated the main assumptions of our approach, we can employ hierarchical clustering to find reduce down the number of network nodes. For the clustering algorithm, we will use Ward's method, since it is known to form spherical clusters and well accommodate outliers. This method forms clusters by minimising the within cluster variance.

While HC is deterministic, a clustering has to be specified by separating variables at a given level - i.e., where to cut the clustering tree. Nodes separated below this cut value will be in the same cluster, while nodes separated above this value will be in different clusters. While there is no perfect way to do this, we can employ various metrics that measure the tightness of clusters, as well as some that measure the cluster consistency under different perturbations such as resamples. Our optimisation process here will involve iterating across cutoff values which are known (from prior testing) to generate less than 100 clusters but more than 1 cluster. We iterate in steps of 0.01 which will produce a small change in the cluster number in most cases. At each step, the metrics will be combined into a normalised score which indicates the quality of each clustering. Because the process of finding the optimal cluster depends to some degree on random sampling of control data, we will iterate the process over 10 random seeds to see if there is a stable optimal cluster number. 


```{r ward_clustering_optimisation, message=F, warning=F, cache=T}
# Iterate over clusterings and find optimal number #

# Set random seeds for resampling
seeds = c(674345, 811071, 276503, 411732, 475378, 
          690070, 425943, 729736, 621889, 660812)

# Set cutoff values to test --- change if needed
cut_values = seq(from = 1.40, to = 2.50, by = 0.01)

# Iterate optimisation over the 10 seeds
hc_clustns = vector() 
hc_cuts = vector()
for (i in 1:10){  # for each seed
  hc_optimum = optimal_cluster(data = data, 
                clust_method = 'ward.D',
                cut_values = cut_values,
                seed = seeds[i])
  hc_clustns[i] = hc_optimum[[3]] 
  hc_cuts[i] = hc_optimum[[1]]
}

# Get consensus clustering
clustn = Mode(hc_clustns) 
cut = Mode(hc_cuts)
print(paste0('Optimal cluster numbers: ', hc_clustns))
print(paste0('Consensus cluster number = ', clustn))
```

It seems here the optimal number of clusters is `r print(clustn)`, which is an appropriate number for a network analysis. 

To see how these clusters are structured, we will now re-generate this clustering using the control data, and plot the dendrogram and the cluster locations on the 2D flattened cortical sheet.

```{r cluster_locations}
# Form optimal clusters and plot dendrogram #

# Re-run clustering with suggested clusters
hc = hclust.plot(data_lr, group = 'Control', clust_method = 'ward.D', 
                        cut = cut, clustn = clustn, plot_tree = T)[[1]]

# Re-order clustering to match original
hc = hc[match(colnames(data_lr[, -metadata_cols]), hc$Area), ]

# Plot cluster anatomical positions
hc = merge(parcel_positions, hc) # merge with 2D coordinates
hc$cluster = factor(hc$cluster)
ggplot(data = hc, aes(x = x, y = max(y) - y, fill = cluster))+
  geom_point(size = 0.8, shape = 21, stroke = 0.5)+
  geom_text(aes(
    label = gsub(x = cluster, pattern = 'cluster ', replacement = '')), 
    size = 2, vjust = -0.6)+
  scale_fill_viridis_d(option = "C")+
  labs(x = 'x', y = 'y')+
  theme(legend.position = 'none',
        axis.text = element_blank())

# Write clustering arrangement to .csv
write.csv(hc, file = paste0(savepath_data, 'hclust/hc.csv'), row.names = F)
```

The clusters seem to form according to anatomical location, with proximal parcels falling into the same cluster. The number of parcels in a cluster varies from about 1 to 6. This indicates the clustering is uncovering some anatomical structure in the data, with proximal parcels having more similar correlations with the rest of the cortex.


# Effects of covariates on cluster partial correlations

Now we have a good idea of the cluster structure, we need to use the clustering to generate some group data for comparison. However, since sample size affects the calculation of correlation coefficients, we cannot compare the entire control data (n = 650) with the synaesthete group (n = 102) --- we have to reduce down the number of controls. A random selection, while unbiased, may not be the best choice since other variables such as age and sex could also affect results - and these factors are also a part of our other investigations. 

To see to what degree age and sex affect correlation structure in our sample, we will generate samples of controls which differ only by one variable (e.g., male or female), but are matched for other variables. To achieve this, we will use an optimal matching approach to generate matched groups. This works by first calculating a propensity score from a logistic regression of the covariates, which describes the probability for a given individual to belong to a group. Distances between individuals in the different groups are calculated from the propensity scores, the optimal matching algorithm returns the sets of individuals which globally minimises the total sum of distances. 


## Sex

We start by looking at sex. We will first check how many of each sex we have in our control sample.

```{r sex_n}
# Check sex balance #

print(paste0('Number of females = ', nrow(data[data$Sex == 1,])))
print(paste0('Number of males = ', nrow(data[data$Sex == 2,])))
```

Since we only have 178 males, we will have to select an equal (or smaller) number of females for a 1:1 matched comparison. These should also be as close in possible in age and dataset origin. 

Once we have our matched samples, let's summarise data within our set of clusters and examine the partial correlations for each. The `pcor_comp()` function returns a plot of the partial correlation distributions, and also performs a KS test for distribution shape, a t-test for means, and an F-test for variances. Note that it requires that data be split into a list, along with a grouping vector that describes the group membership of each element in the list.

```{r match_sexes, message=F, warning=F}
# Compare correlations of matched sexes #

# Convert categorical variables to factors
data$Sex = factor(data$Sex)
data$Scan = factor(data$Scan)

# Match the control data by sex
data_cntrl = data[data$Group == 'Control',] 
matched = matchit(Sex ~ Age + Scan, data = data_cntrl,
                  method = "optimal", ratio = 1)
data_sex_matched = match.data(matched)
print(table(data_sex_matched$Sex))
matchit_cols = (ncol(data_sex_matched)-2):ncol(data_sex_matched)
data_sex_matched = data_sex_matched[,-matchit_cols]
data_sex_matched = lr_average(data_sex_matched)

# Summarise the matched data within the clusters
data_sex_matched_hc = summarise_clusters(data_sex_matched, hc)
data_sex_matched_hc = split(data_sex_matched_hc[[1]], 
                             data_sex_matched_hc[[1]]$Sex)

# Run the correlation comparison
sex_comp = pcor_comp(data_list = data_sex_matched_hc, nclust = nclust, 
           group_vec = c('Female', 'Male'),
           colours = c('pink', 'cyan'))
print(sex_comp[[1]])  # display plot
print(sex_comp[[2]][[1]][[1]])  # display distributional tests
pcor_diffs = sex_comp[[2]][[1]][[2]]  # get correlation differences
table(pcor_diffs$signif) / nrow(pcor_diffs)  # summarise diffs
```

It looks like the partial correlations of males and females are broadly quite similar here, with males appearing to have some bias towards more negative correlations. The tests indicate there are no differences in the distributions; however, this does not rule out that some individual pair-wise correlations are different. Indeed, we see that around 74% of pair-wise correlations are different between the groups.


## Age

Since age is a numerical variable so is not naturally separated into groups, we will group ages into three categories: <22, 22-35, and >35 to see if there are any differences. However, because matching requires the comparison of two groups, we will have to perform pairwise comparisons.

```{r match_age_groups, message=F, warning=F}
# Compare correlations of matched age groups #

# Create age groups
data_cntrl = data[data$Group == 'Control',]
data_cntrl$Age_group = ifelse(data_cntrl$Age < 22,
                                'Young', 'Middle')
data_cntrl$Age_group = ifelse(data_cntrl$Age > 35,
                                'Old', data_cntrl$Age_group)
data_cntrl$Age_group = factor(data_cntrl$Age_group, 
                                levels = c('Young', 'Middle', 'Old'))
data_cntrl$Age = data_cntrl$Age_group
data_cntrl = data_cntrl[,-ncol(data_cntrl)] # to remove age groups column

# Iterate over pairwise comparisons
age_combos = combn(c('Young', 'Middle', 'Old'), 2)
plots = list()
distr_tests = list()
pcor_diffs = list()
for (i in 1:ncol(age_combos)){  # for each age group combination
  matched = matchit(Age ~ Sex + Scan, 
                    data = 
                      # use first element of i-th age combination
                      data_cntrl[data_cntrl$Age == age_combos[,i][1] 
                                 # and second element of i-th age combination
                                   | data_cntrl$Age == age_combos[,i][2],], 
                    method = "optimal", ratio = 1)
  data_age_matched = match.data(matched)
  matchit_cols = (ncol(data_age_matched)-2):ncol(data_age_matched)
  data_age_matched = data_age_matched[,-matchit_cols] 
  data_age_matched = lr_average(data_age_matched)
  print(table(data_age_matched$Age))
  
  # Summarise into clusters
  data_age_matched_hc = summarise_clusters(data_age_matched, hc)
  data_age_matched_hc[[1]]$Age = factor(data_age_matched_hc[[1]]$Age, 
                                         levels = unique(age_combos[,i]))
  data_age_matched_hc = split(data_age_matched_hc[[1]], 
                               data_age_matched_hc[[1]]$Age)
  
  # Run the correlation comparison
  result = pcor_comp(data_list = data_age_matched_hc, nclust = nclust, 
                          group_vec = age_combos[,i],
                          colours = c('forestgreen', 'orange'))
  plots[[i]] = result[[1]]
  distr_tests[[i]] = result[[2]][[1]][[1]]
  pcor_diffs[[i]] = result[[2]][[1]][[2]]
}

# Display results
grid.arrange(grobs = plots, ncol = 3, widths = c(3,3,3))
print(distr_tests)
sapply(pcor_diffs, function(x) table(x$signif) / nrow(x))
```

Some apparently bigger differences for the age groups here than for sex. The only distributional test that shows a difference is the F-test for variance for the comparison between <22 and >35 years old, which is P = 0.056. However, comparison of individual correlations shows that for comparisons with younger individuals, around 80% of correlations differ, while it is around 66% for the comparison of the middle and older groups.


## Scan type

We will check the numbers of different scan types in the data.

```{r check_scan_types}
# Check numbers of scan types #

print(table(data$Scan))
print(table(data_cntrl$Scan))
```

Unfortunately, the distribution of the different scan types is very unbalanced. While most of the individuals come from the HCP database, just a few were scanned at CISC. Furthermore, we have to note that the majority of those scanned at CISC were synaesthetes, leaving just a few CISC controls with which to compare to the HCP scans. Because partial correlations will be estimated poorly (or not at all) for groups of n < 63, it is not worth trying to compare the different scan types. However, because the data have been harmonised, we know that group differences in the raw data between scan types will be small.


# Matching controls and synesthetes

In the above analysis, we have seen that sex and age can have some subtle yet potentially important effects on correlation structure. Therefore, to generate our two groups of n = 102 for comparison, we should match controls and synaesthetes according to these covariates. We will form the matched groups and examine their correlation structure.

```{r match_groups, message=F, warning=F}
# Match controls and experimentals by sex and age #

# Perform optimal matching by sex and age
data$Group = factor(data$Group,levels = c('Control', exp_group)) 
matched = matchit(Group ~ Sex + Age, data = data, 
                  method = "optimal", ratio = 1)
data_matched = match.data(matched)
matchit_cols = (ncol(data_matched)-2):ncol(data_matched)
data_matched = data_matched[, -matchit_cols]

# Left-right average and summarise into clusters
data_matched = lr_average(data_matched) 
data_matched_hc = summarise_clusters(data_matched, hc)[[1]]  # 1=sums, 2=means

# Check covariate balance
print(mean(data_matched[data_matched$Group == 'Control',]$Age))
print(mean(data_matched[data_matched$Group == exp_group,]$Age))

print(table(data_matched[data_matched$Group == 'Control',]$Sex))
print(table(data_matched[data_matched$Group == exp_group,]$Sex))
```

Due to the matching procedure, there is a good match of ages between the two groups. Although the sexes are unbalanced within each group, the relative proportions are also very similar between the groups.


## Distribution checks

Prior to comparing the groups in terms of their correlation structure, we need to ensure our distributional assumptions still hold for this matched, clustered data. As we did previously for the parcel data prior to clustering, we will check that cluster data is normally distributed, and that there are no trivial group differences in the distributions of cluster morphology.

```{r matched_cluster_distributions, warning=F, message=F}
# Compare clustered data distributions #

# Normality tests for cluster-summarised control data
MVN_test(data_matched_hc[data_matched_hc$Group == 'Control', -metadata_cols])
table(mvn(data_matched_hc[, -metadata_cols])
      [['univariateNormality']]$Normality)

# Run F-tests for variance
test_summaries = list()  
for (region in colnames(data_matched_hc[, -metadata_cols])) { 
  res = var.test(data_matched_hc[[region]][data_matched_hc$Group == 'Control'], 
                 data_matched_hc[[region]][data_matched_hc$Group == exp_group])  
  test_summaries[[region]] = res
}
sig_results = lapply(test_summaries, function(x) x$p.value[x$p.value < 0.05])
print(sig_results[sapply(sig_results, length) > 0])

# Fit linear model for each area
model_summaries = list()
for (region in colnames(data_matched_hc[, -metadata_cols])) { 
  model = lm(data_matched_hc[[region]] ~ Group, data = data_matched_hc)  
  model_summaries[[region]] = summary(model)
}
p_vals = sapply(model_summaries, FUN = function(list){ 
  list[["coefficients"]][2,4] 
})
print(p_vals[p_vals < 0.05])
```

The tests for normality are similar to what we observed with the full control data. While not all the MVN tests suggest perfect multivariate normality, the Mahalanobis plot and univariate normality suggest a normality assumption is adequare, as only 15 (24.2%) clusters are suggested to be not normal.

As for differences in variances, only 6 (9.7%) clusters show some difference in variance. Conversely, 17 (27.4%) clusters show a difference in means. 


## Partial correlation comparison

```{r}
# Compare partial correlations from matched clustered data #

# Perform comparisons of partial correlations
data_matched_hc = split(data_matched_hc, data_matched_hc$Group)
data_matched_comp = pcor_comp(data_list = data_matched_hc, nclust = nclust, 
           group_vec = c('Control', exp_group))
print(data_matched_comp[[1]])  # display plots
print(data_matched_comp[[2]][[1]][[1]])  # display distribution tests
pcor_diffs = data_matched_comp[[2]][[1]][[2]]  # get pairwise pcor differences
sort_pair = function(x) {  # function to sort area pairs
  parts = as.numeric(unlist(strsplit(x, "-")))
  paste0(sort(parts), collapse = "-")
}
pcor_diffs$area_pair = sapply(pcor_diffs$area_pair, sort_pair)  # sort
pcor_diffs = pcor_diffs[!duplicated(pcor_diffs$area_pair),]  # remove duplicares
print(table(pcor_diffs$signif) / nrow(pcor_diffs))  # percentage different

# Set filenames for saving matched data --- change if needed
data_matched_cntrl_filename = 'SA_abs_hc_cntrl_matched.csv'
data_matched_exp_filename = 'SA_abs_hc_syn.csv'


# Write to .csv
write.csv(data_matched_hc[[1]], 
          file = paste0(savepath_data, 'hclust/', data_matched_cntrl_filename), 
          row.names = F)
write.csv(data_matched_hc[[2]], 
          file = paste0(savepath_data, 'hclust/', data_matched_exp_filename), 
          row.names = F)
```


As for the group differences, we can see that both the KS test and the F test report a highly significant difference in the distributions, suggesting that there is a large difference in the spread of partial correlations. The plots indicate that the synaesthetes have a wider spread of correlations. However, there is no difference in the means, as supported by the t-test. Looking at individual correlations, we see that around 84% are different between the groups. We can also check which correlations in particular are different between groups, and which are the invariant.

```{r matched_groups_cor_diffs}
# Group differences in pairwise correlations #

# Top 10 ranked differences
top_diffs = pcor_diffs[order(abs(pcor_diffs$Z_score), decreasing = T),]
top_diffs[seq(1,20, by = 2),]$area_pair  # take every other row for duplicates

# Bottom 20 ranked differences
bot_diffs = pcor_diffs[order(abs(pcor_diffs$Z_score)),]
bot_diffs[seq(1,20, by = 2),]$area_pair  # take every other row for duplicates
```

The major group differences in pairwise correlation strength appear to mostly be long-range connections involving frontal, temporal, and parahippocampal regions. Interestingly, the invariant connections are largely shorter-range correlations between sensory areas such as somatosensory, visual, and auditory regions.


## Network analysis

In python, we have imported the matched clustered data for basic network analysis. This process builds weighted networks from the partial correlations, and estimates metrics like the clustering coefficient and characteristic path length. Variances in these metrics are estimated from jackknife resampling, and statistical significance of group differences is estimated with permutation tests. We will import the results here for visualisation.

```{r basic_network_metrics}
# Import and visualise matched sample network metrics #

# Read in results
net_metrics = read.csv(paste0(savepath_data, 'hclust/', 
                              'hc_matched_net_metrics.csv'))
net_metrics_jk = read.csv(paste0(savepath_data, 'hclust/', 
                              'hc_matched_jackknife_metrics.csv'))
net_metrics_perm = read.csv(paste0(savepath_data, 'hclust/', 
                              'hc_matched_net_perm.csv'))

# Wrangle data
net_metrics = melt(net_metrics, .id_vars = 'Group', variable.name = 'Metric')
net_metrics_se = select(net_metrics_jk, 1,2,4)  # get standard error
net_metrics = merge(net_metrics, net_metrics_se)  # merge with group metrics
net_metrics_perm = melt(net_metrics_perm, 
                        .id_vars = 'Stat', variable.name = 'Metric')
pvals = net_metrics_perm[net_metrics_perm$Stat == 'P-value',]

# Create p-value positions
net_lims = net_metrics %>%
  group_by(Metric) %>%
  summarise(y_max = max(value+SE, na.rm = TRUE))

pvals = pvals %>%
  left_join(net_lims, by = "Metric") %>%
  mutate(y_pos = y_max * 1.1) 

# Plot results
ggplot(data = net_metrics, aes(x = Group, y = value, fill = Group))+
  geom_col(width = 0.8, alpha = 0.5, colour = 'black', lwd = 0.8)+
  geom_errorbar(aes(ymin = value - SE, ymax = value + SE),
                width = 0.6, colour = 'black', lwd = 0.8)+
  geom_segment(data = pvals,
               aes(x = 1, xend = 2, y = y_pos, yend = y_pos),
               inherit.aes = FALSE, lwd = 0.8) +
  geom_text(data = pvals,
            aes(x = 1.5, y = y_pos * 1.1, label = value),
            inherit.aes = FALSE)+
  
  scale_y_continuous(expand = expansion(add = c(0,0)))+
  scale_fill_manual(values = c('blue', 'red'))+
  scale_colour_manual(values = c('blue', 'red'))+
  coord_cartesian(clip = 'off')+
  
  labs(x = '', 
       y = '',
       title = 'Network metrics')+
  #guides(fill = guide_legend(override.aes = list(alpha = 1)))+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 10, colour = 'black'),,
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'none',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0)),
    strip.background = element_blank(),
    strip.text = element_text(margin = margin(10,0,10,0)))+
  facet_wrap(~Metric, scales = 'free_y', 
             labeller = as_labeller(c(clustering = 'Clustering',
                                      efficiency = 'Efficiency',
                                      L_obs = 'Path length',
                                      mean_eb = 'Mean edge betweenness',
                                      mean_vb = 'Mean vertex betweenness')))
```

We observe some fairly clear group differences in clustering coefficient, efficiency and path length, although only path length technically has a P < 0.05. No differences are seen for average betweenness. 

However, we know from the partial correlation distributions that synaesthetes have larger correlations, corresponding to larger edge weights in their network. This could be trivially driving differences in clustering, efficiency and path length, since the weighted versions of these calculations produce larger values when weights are greater. If this is true, the group differences in these values would not reflect the network topology, but rather just the presence of stronger correlations within the synaesthete group. One method to probe this possibility is to normalise the weights of both networks before metric calculation, so that there are no differences on average. Group differences here would point to the importance of network topology. Another method is to randomise the edge weights and recompute the metrics. Group differences here would suggest that specific differences in topology are not the driving factor for metric disparities. In python, we have followed both of these approaches, making sure to average over multiple random networks to account for different random topologies. We will import and visualise the results here.

```{r}
# Import and visualise normalised and randomised network metrics #




```



## Cluster number perturbation

Tests on the matched data up to this point indicate that the clustering is appropriate, and that there are group differences in basic network metrics. However, we also want to be sure that our specific choice of clustering is not driving these group differences. Therefore, we will check that the basic network differences are robust to small changes in the number of clusters. Since spatial resolution / node number is known to affect network properties, we want to choose some cluster numbers close to the optimal for testing. We will iterate over four cutoff values close to the optimal (3 above, 3 below) and examine the summarised data for the matched control sample. 

```{r alternative_clusters, message=F, warning=F}
# Generate alternative cluster numbers #

# Set cutoff values --- change if needed
cuts = c(cut - 0.03, cut - 0.025, cut - 0.02, 
         cut + 0.01, cut+ 0.02, cut + 0.035)

# Initialise results
data_matched_hc_alts = list()
plots = list()
distr_tests = list()

# Iterate over cutoffs
for (i in 1:length(cuts)){
  # Perform clustering
  hc_alt = hclust.plot(data_lr, group = 'Control', 
                              clust_method = 'ward.D', cut = cuts[i], 
                              clustn = clustn, plot_tree = F)
  
  # Print number of clusters
  nclust_alt = max(hc_alt[[1]]$cluster)
  print(paste0('Number of clusters = ', nclust_alt))
  
  # Merge with position data
  hc_alt = merge(parcel_positions, hc_alt[[1]])
  hc_alt$cluster = factor(hc_alt$cluster) 
  
  # Summarise the matched data
  data_matched_hc_alt = summarise_clusters(data_matched, 
                                                hc_alt)[[1]]  # 1=sums, 2=means
  
  # Get control data and plots
  data_matched_hc_alt = split(data_matched_hc_alt, 
                              data_matched_hc_alt$Group)
  data_matched_hc_alts[[i]] = data_matched_hc_alt
  alt_comp = pcor_comp(data_list = data_matched_hc_alt, 
                          nclust = nclust_alt, 
                       group_vec = c('Control', exp_group))
  plots[[i]] = alt_comp[[1]]
  distr_tests[[i]] = alt_comp[[2]][[1]][[1]]
}

grid.arrange(grobs = plots, ncol = 3)
print(distr_tests)

# Set filenames for exporting alternative clusters --- change if needed
alt_cntrl_filename = 'SA_abs_hc_cntrl_matched_alt_'
alt_exp_filename = 'SA_abs_hc_syn_matched_alt_'

# Write to .csv
for (i in 1:length(data_matched_hc_alts)){
  write.csv(data_matched_hc_alts[[i]][[1]], 
          file = paste0(savepath_data, 
                        'hclust/', alt_cntrl_filename, i, '.csv'), 
          row.names = F)
  write.csv(data_matched_hc_alts[[i]][[2]], 
          file = paste0(savepath_data, 
                        'hclust/', alt_exp_filename, i, '.csv'),  
          row.names = F)
}
```

This process has tested cluster numbers 59, 60, 61, 63 64, and 65. In each case, we see that the synaesthete partial correlations are distributed more widely than the matched controls, as was observed in the optimal 62 cluster case. This is supported by consistent findings of distribution differences with the F test and KS test. This demonstrates that the main structure of our results is not drastically affected by small changes to the number of clusters away from the optimal number of 62. To confirm that network structure does not change, we performed network analysis in python using clustered data for each set of clusters. We will import and visualise the results.

```{r alternative_clusters_net_metrics, message=F, warning=F}
# Report alternative cluster network metrics #

# Set filename for alternative cluster metrics --- change if needed
alt_metrics_filename = 'HC_matched_alt_net_metrics.csv'

# Set alternative cluster numbers --- change if needed
alt_cluster_ns = c(59,60,61,62,63,65) 

net_metrics = read.csv(paste0(savepath_data, 
                              'hclust/', alt_metrics_filename))
net_metrics$cluster_number = rep(alt_cluster_ns, 2)
net_metrics = net_metrics[,c("clustering", "efficiency", 
                             "cluster_number", "Group")]
colnames(net_metrics)[c(1,2)] = c('Clustering', 'Efficiency')
net_metrics = melt(net_metrics, id.vars = c('cluster_number','Group'))
net_metrics$Group = factor(net_metrics$Group, levels = c('Control', exp_group))
net_metrics$cluster_number = factor(net_metrics$cluster_number)

# Plot results
ggplot(data = net_metrics, aes(x = variable, y = value, fill = Group))+
  geom_col(width = 0.8, position = position_dodge(0.8), 
           alpha = 0.5, colour = 'black', lwd = 0.8)+
  
  scale_y_continuous(expand = expansion(add = c(0,0)))+
  scale_fill_manual(values = c('blue', 'red'))+
  scale_colour_manual(values = c('blue', 'red'))+
  coord_cartesian(clip = 'off')+
  
  labs(x = '', 
       y = '',
       title = 'Network metrics for alternative clusters')+
  #guides(fill = guide_legend(override.aes = list(alpha = 1)))+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 12, colour = 'black'),
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'top',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0)),
    strip.background = element_blank())+
  facet_wrap(~cluster_number)
```

We have plotted clustering coefficient and efficiency here since they go nicely on the same scale. We observe very similar values across clusters, with synaesthete values consistently higher than controls. This confirms that basic network analysis is robust to small changes in the hierarchical clustering.


# Further network analysis

Our analysis to this point indicates there are some notable differences between the matched controls and synaesthetes in terms of their correlation network structure. We will now extend our analysis to look at deeper aspects of network organisation.

## Weight by distance relationship and small-worldness

One interesting line of investigation is considering how the correlational networks are related to the structure of the brain. One immediate method of examining this question is to look at the networks plotted according to brain anatomy, such that each cluster is close to where its parcels are located. We have generated network visualisations in python, so we will import them here for visualisation.

```{r matched_control_network, fig.cap = 'Partial correlation network of 62 SA clusters in controls'}
# Import control network visualisation #

# Set filename for control network --- change if needed
control_net_filename = 'SA_abs_matched_hc_cntrl_net.png' 
knitr::include_graphics(paste0(python_imports, control_net_filename))
```

```{r matched_syn_network, fig.cap = 'Partial correlation network of 62 SA clusters in synesthetes'}
# Import experimental network visualisation #

exp_net_filename = 'SA_abs_matched_hc_syn_net.png'
knitr::include_graphics(paste0(python_imports, exp_net_filename))
```

Here we can see the generally stronger correlations in the synaesthete network, which appear to be at longer ranges compared to the control network.

To confirm this possible trend, we can plot the distribution of weights according to physical distance. In python, we have calculated the 2D distance between every node (as plotted on the flattened cortex) and merged these with the edge weights (i.e. partial correlation strengths). Here, we will visualise the distance-weight relationship for each group, and use a Generalized Additive Model (GAM) to model the relationship. GAMs work by fitting a curve (spline) to the data through the optimisation of smooth functions between different regions of the predictor(s). The mgcv R package has an automated optimisation procedure for fitting splines, which maximises fit to the data while also penalising overfitting (excessive bendiness in the curve). The comparison of different smooth parameters 


```{r weight_by_dist, fig.cap = 'Distance-correlation relationships for controls and synesthetes', warning=F, message=F}
# Import and combine 2D distance data #

# Set filenames for distances --- change if needed
dists_cntrl_filename = 'hc_matched_cntrl_dists.csv' 
dists_exp_filename = 'hc_matched_syn_dists.csv'

dists_cntrl = read.csv(paste0(savepath_data,
                              'hclust/', dists_cntrl_filename))
dists_exp = read.csv(paste0(savepath_data,
                            'hclust/', dists_exp_filename))
dists = rbind(dists_cntrl, dists_exp)
dists$Group = rep(c('Control', exp_group), each = nrow(dists)/2)
dists$Group = factor(dists$Group, levels = c('Control', exp_group))

# Plot empirical weight vs distance with smooth curves
ggplot(data = dists, aes(x = distance, y = weight, colour = Group))+
  geom_smooth(lwd = 1.1)+
  scale_color_manual(values = c('blue', 'red'))+
  labs(x = 'Two-dimensional distance (pixels)',
       y = 'Absolute partial correlation',
       title = 'Weight as a function of cortical distance')+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 10, colour = 'black'),,
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'top',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0))
  )

# Fit a generalized additive model to compare groups
gam_model = gam(weight ~ s(distance, by = Group, k = 5) + Group, data = dists,
             family = 'gaussian')
print(summary(gam_model))  # for signifiance of model terms
gam_model_no_int = gam(weight ~ s(distance, k = 5) + Group, data = dists, 
                       family = 'gaussian')  # without group separation
dev_test = anova.gam(gam_model, gam_model_no_int, 
          test = 'Chisq')
print(dev_test)

# Predict weight-distance relationship from fitted GAM
distance_grid = seq(min(dists$distance), 
                    max(dists$distance), 
                    length.out = 100)
GAM_data = expand.grid(
  distance = seq(min(dists$distance), max(dists$distance), length.out = 100),
  Group = c('Control', exp_group)
)
weight_pred = predict(gam_model, newdata = GAM_data, se.fit = TRUE)
GAM_data$weight = weight_pred$fit
GAM_data$se = weight_pred$se.fit

GAM_control = GAM_data[GAM_data$Group == 'Control',]
GAM_exp = GAM_data[GAM_data$Group == exp_group,]
GAM_CIs = data.frame(distance =
                       unique(GAM_data$distance),
                     diff = 
                       GAM_control$weight - GAM_exp$weight,
                     se_diff = 
                       sqrt(GAM_control$se^2 + GAM_exp$se^2)
                     )
GAM_CIs$CI_upper = GAM_CIs$diff + 1.96 * GAM_CIs$se_diff
GAM_CIs$CI_lower = GAM_CIs$diff - 1.96 * GAM_CIs$se_diff
GAM_CIs$effect_size = GAM_CIs$diff / 
  sqrt((GAM_control$se^2 + GAM_exp$se^2) / 2)

GAM_CIs$p_value = with(GAM_CIs, 2 * pnorm(-abs(diff / se_diff)))
GAM_CIs$signif = GAM_CIs$p_value < .05

# Plot predicted curves
ggplot(GAM_data, aes(x = distance, y = weight, color = Group)) +
  geom_ribbon(aes(ymin = weight-se, ymax = weight+se, group = Group),
              fill = 'grey', colour = NA)+
  geom_line(size = 1.2) +
  annotate('text', x = 210, y = 0.28, 
           label = substitute(P[smooth] == pval, 
                              list(pval = round(dev_test[2,5], 3))),
         size = 5, hjust = 'left')+
  
  scale_color_manual(values = c("blue", "red"))+
  
  labs(title = "Predicted GAM curves", 
       x = 'Geodesic distance on the spherical cortical surface',
       y = "Predicted partial correlation") +
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 10, colour = 'black'),,
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'top',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0))
  )

# Plot derivatives - how is weight changing
gam_deriv = derivatives(gam_model, term = "s(distance)", partial_match = T)
draw(deriv)
```

Examination of the distance-weight relationships shows that both controls and synaesthetes have the strongest weights at short distances, and this rapidly drops off as distances increases. However, while this continues to decline in controls, in synaesthetes the weights increase again at the longest distances. Examining the fit of a GAM, we see that both the parametric effect of group as well as the smoothing terms are statistically significant, suggesting that 1) synaesthetes have significantly different weights to controls and 2) that incorporating smoothing terms significantly improves model fit, supporting a non-linear relationship between distance and weight. In comparing a GAM with separate group smoothing terms to one with just one smooth term (but still a parametric group effect), we observe a statistically significant difference via analysis of deviance, suggesting that the two groups have different distance-weight relationships.


## Small-worldness

With physical distance data, we can also examine the concept of small-worldness through small-world propensity (SWP). This metric is calculated by comparing the clustering coefficient and characteristic path length of the observed network to two null models: a locally-strong lattice network and a distantly-strong randomly rewired network. 

In python, we have calculated *SWP* independently for each of our observed graphs. This means that each observed graph is compared to its own null models, thus controlling for differences in node strengths. We have also calculated *delta*, which indicates which null model properties are driving deviations from perfect small-worldness. As with the basic network metrics, we have estimated variances of SWP and delta through jackknife resampling, as well as statistical significance through permutation tests. We will import the results here for visualisation.

```{r SWP, fig.cap = 'SWP and delta values in controls and synesthetes'}
# Report small-world propensity #

# Read in SWP results 
SWP = read.csv(paste0(savepath_data, 'hclust/', 'hc_matched_SWP.csv'))
SWP_jk = read.csv(paste0(savepath_data, 'hclust/', 
                         'hc_matched_jackknife_SWPs.csv'))
SWP_perm = read.csv(paste0(savepath_data, 'hclust/', 'hc_matched_SWP_perm.csv'))

# Wrangle data
SWP = melt(SWP, id.vars = 'Group', variable.name = 'Metric')
SWP_se = select(SWP_jk, 1,2,4)
SWP = merge(SWP, SWP_se)
SWP_perm = melt(SWP_perm, 
                .id_vars = 'Stat', variable.name = 'Metric')
pvals = SWP_perm[SWP_perm$Stat == 'P-value',]

# Create p-value positions
SWP_lims = SWP %>%
  group_by(Metric) %>%
  summarise(y_max = max(value+SE, na.rm = TRUE))

pvals = pvals %>%
  left_join(SWP_lims, by = "Metric") %>%
  mutate(y_pos = y_max * 1.1) 

# Plot SWP
ggplot(data = SWP[SWP$Metric == 'SWP',], aes(x = Group, y = value, fill = Group))+
  geom_col(position = position_dodge(), color = 'black', alpha = 0.5, lwd = 0.8)+
  geom_errorbar(aes(ymin = value - SE, ymax = value + SE),
                width = 0.6, colour = 'black', lwd = 0.8)+
  geom_segment(data = pvals[pvals$Metric == 'SWP',],
               aes(x = 1, xend = 2, y = y_pos, yend = y_pos),
               inherit.aes = FALSE, lwd = 0.8) +
  geom_text(data = pvals[pvals$Metric == 'SWP',],
            aes(x = 1.5, y = y_pos * 1.1, label = value),
            inherit.aes = FALSE, size = 5)+
  
  scale_y_continuous(expand = expansion(add = c(0,0)))+
  coord_cartesian(ylim = c(0,1), clip = 'off')+
  scale_fill_manual(values = c('blue', 'red'))+
  
  labs(x = 'Group',
       y = 'SWP',
       title = 'Small-world propensity')+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 12, colour = 'black'),
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'none',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 50, 0))
  )

# Plot delta
ggplot(data = SWP[SWP$Metric == 'delta',], aes(x = Group, y = value, fill = Group))+
  geom_col(position = position_dodge(), color = 'black', alpha = 0.5, lwd = 0.8)+
  geom_errorbar(aes(ymin = ifelse(value - SE > -1, value - SE, -1),
                    ymax = value + SE),
                width = 0.6, colour = 'black', lwd = 0.8)+
  geom_segment(data = pvals[pvals$Metric == 'delta',],
               aes(x = 1, xend = 2, y = 1.1, yend = 1.1),
               inherit.aes = FALSE, lwd = 0.8) +
  geom_text(data = pvals[pvals$Metric == 'delta',],
            aes(x = 1.5, y = 1.2, label = value),
            inherit.aes = FALSE, size = 5)+
  
  scale_y_continuous(expand = expansion(add = c(0,0)))+
  coord_cartesian(ylim = c(-1,1), clip = 'off')+
  scale_fill_manual(values = c('blue', 'red'))+
  
  labs(x = 'Group',
       y = 'Delta',
       title = 'Delta')+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 12, colour = 'black'),
    axis.line.x = element_blank(),
    axis.line.y = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.x = element_blank(),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'none',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 50, 0))
  )
```

SWP appears to be slightly higher in controls than synaesthetes, although it is not statistically significant. In both groups, delta is low, suggesting that deviations from perfect small-worldness are driven by a greater degree of randomness than expected. Although this is slightly less the case in the synaesthete network, there is no statistical difference. We should note for now that the estimated variance is very large. This is likely because SWP estimation itself varies fairly substantially from instance to instance due to random graph generation; this could be remedied by averaging over several random graphs, although this would drastically increase the computational cost. 


## Analysis of local vertex properties

So far, we have shown that control and synaesthete networks differ in several global properties. However, it would be interesting to see if these differences apply equally across the network, or if specific clusters contribute to these patterns.

In python, we created a network showing the differences between the control and synaesthete networks. Node colour and size correspond to differences in local clustering and betweenness, while edge size corresponds to the size of the difference between partial correlation size. All differences are absolute. 

```{r diffnetwork, fig.cap = 'Network showing group differences in correlation strength, local clustering and betweenness'}
# Import difference network visualisation #

# Set filename for difference network --- change if needed
diffnet_filename = 'SA_abs_matched_hc_diffnet.png'
knitr::include_graphics(paste0(python_imports, diffnet_filename))
```

The biggest differences in clustering appear to be in the prefrontal cortex, hippocampus and PCC. The biggest differences in betweenness are in the hippocampus and PCC. The biggest differences in edge weights are from the mPFC to hippocampus, PCC to hippocampus, DLPFC to parietal cortex.


## Positive and negative split graphs

So far, we have been looking at networks formed from absolute partial correlation, under the assumption that any association is important for distinguishing groups. However, there may be specific information contained within the positive or negative associations alone. To address this, we will examine networks formed from just the positive or negative correlations.

First, we will compare the distributions of positive and negative correlations across groups.

```{r signed_pcor_distributions, fig.cap = 'Distributions of positive and negative partial correlations'}
# Examine signed partial correlations #

# Generate partial correlations
pcor_list = lapply(data_matched_wrd, FUN = function(df){pcor(df[, -metadata_cols])$estimate})
pcor_list = lapply(pcor_list, FUN = function(df){df = melt(df)})
pcors = bind_rows(pcor_list, .id = 'Group')

# Assign sign variable
pcors$sign = ifelse(pcors$value > 0, 'Positive', 'Negative')
pcors = pcors[!pcors$value == 1,] # remove self-correlations

# plot partial correlation distributions
pcors$Group = factor(pcors$Group, levels = c('Control', exp_group))
pcors$sign = factor(pcors$sign, levels = c('Positive', 'Negative'))

# Plot distributions
ggplot(data = pcors, aes(x = value, color = Group))+ 
  geom_density(lwd = 1.05)+
  
  scale_color_manual(values = c('blue', 'red'))+
  labs(x = 'Partial correlation', y = 'Density')+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 12, colour = 'black'),
    axis.line.y = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(2, 'mm'),
    legend.position = 'top',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 50, 0)),
    strip.background = element_blank()
    )+
  facet_wrap(~sign, scales = 'free_x')
```

Overall the two distributions look quite similar. The synesthetes may have a higher number of strong correlations (0.5) compared to controls in the negative more so than the positive, while the opposite is true for somewhat weaker correlations (0.2).

In python, we have visualised networks formed from only positive or negative correlations. We will visualise them here to look for differences.

```{r split_net_control_pos, fig.cap = 'Network of positive partial correlations in controls'}
# Import positive control network visualisation

# Set filename for positive control network --- change if needed
pos_cntrl_filename = 'SA_abs_matched_hc_cntrl_split_pos.png' 
knitr::include_graphics(paste0(python_imports, pos_cntrl_filename))
```

```{r split_net_control_neg, fig.cap = 'Network of negative partial correlations in controls'}
# Import negative control network visualisation

# Set filename for positive control network --- change if needed
neg_cntrl_filename = 'SA_abs_matched_hc_cntrl_split_neg.png'
knitr::include_graphics(paste0(python_imports, neg_cntrl_filename))
```

```{r split_net_syn_pos, fig.cap = 'Network of positive partial correlations in synesthetes'}
# Import positive experimental network visualisation

# Set filename for positive control network --- change if needed
pos_exp_filename = 'SA_abs_matched_hc_syn_split_pos.png'
knitr::include_graphics(paste0(python_imports, pos_exp_filename))
```

```{r split_net_syn_neg, fig.cap = 'Network of negative partial correlations in synesthetes'}
# Import negative experimental network visualisation

# Set filename for positive control network --- change if needed
neg_exp_filename = 'SA_abs_matched_hc_syn_split_neg.png' 
knitr::include_graphics(paste0(python_imports, neg_exp_filename))
```

It looks like the control positive network is has stronger connections at short range, while the negative network as strong connections at multiple distances. For synesthetes, this pattern looks more compressed, with some long-range positive connections and shorter-range negative connections.

We will now compare the network metrics, as calculated in python. 

```{r split_net_metrics, fig.cap = 'Network metrics of positive and negative networks', message = F}
# Report positive and negative network metrics #

# Set filenames for split network metrics --- change if needed
net_metrics_split_filename = 'hc_matched_split_net_metrics.csv' 
net_metrics_jk_split_filename = 'hc_matched_split_net_metrics.csv'
net_metrics_split_perm_filename = 'hc_matched_split_net_perm.csv'

# Read in data
net_metrics = read.csv(paste0(savepath_data,
                              'hclust/', net_metrics_split_filename))
net_metrics_jk = read.csv(paste0(savepath_data,
                              'hclust/', net_metrics_split_jk_filename))
net_metrics_perm = read.csv(paste0(savepath_data,
                              'hclust/', net_metrics_split_perm_filename))

net_metrics = melt(net_metrics, .id_vars = c('Group', 'Sign'))
net_metrics$Sign = factor(net_metrics$Sign, levels = c('Positive', 'Negative'))


# Create p-value positions
net_lims = net_metrics %>%
  group_by(Metric) %>%
  summarise(y_max = max(value+SE, na.rm = TRUE))

pvals = pvals %>%
  left_join(net_lims, by = "Metric") %>%
  mutate(y_pos = y_max * 1.1) 

# Plot results
ggplot(data = net_metrics, aes(x = Sign, y = value, fill = Group))+
  geom_col(position = position_dodge(),
           alpha = 0.5, color = 'black',  lwd = 0.8)+
  geom_segment(data = pvals,
               aes(x = 1, xend = 2, y = y_pos, yend = y_pos),
               inherit.aes = FALSE, lwd = 0.8) +
  geom_text(data = pvals,
            aes(x = 1.5, y = y_pos * 1.1, label = value),
            inherit.aes = FALSE)+
  
  scale_y_continuous(expand = expansion(add = c(0,0)))+
  scale_fill_manual(values = c('blue', 'red'))+
  coord_cartesian(clip = 'off')+
  
  labs(x = '', 
       y = '',
       title = 'Network metrics in signed networks')+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 10, colour = 'black'),,
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'none',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0)),
    strip.background = element_blank(),
    strip.text = element_text(margin = margin(10,0,10,0))
  )+
  facet_wrap(~variable, scales = 'free_y',
             labeller = as_labeller(c(clustering = 'Clustering',
                                      efficiency = 'Efficiency',
                                      L_obs = 'Path length',
                                      mean_eb = 'Mean edge betweenness',
                                      mean_vb = 'Mean vertex betweenness',
                                      mean_pcor = 'Mean partial correlation')))
```

Interestingly, clustering is lower in positive networks, where it is also the same between groups. Efficiency is greater in positive networks, but appears to be proportionally higher for synesthetes in the negative networks. The average partial correlation strength is greater in positive networks, which may be driven by a few particularly strong connections. 

As for the absolute networks, we will also examine the weight-distance relationship in both groups. We will import distances from python, visualise them, and compare the curves using GAMs. We will do this first for the positive network. 

```{r weight_distance_split_pos}
# Visualise weight-distance relationships for positivesplit networks #

# Import and combine 2D distance data
# filename for control distances --- change if needed
dists_cntrl_filename = 'hc_matched_cntrl_split_dists.csv' 
# filename for experimental distances --- change if needed
dists_exp_filename = 'hc_matched_syn_split_dists.csv' 

dists_cntrl = read.csv(paste0(savepath_data,
                              'hclust/', dists_cntrl_filename))
dists_exp = read.csv(paste0(savepath_data,
                            'hclust/', dists_exp_filename))
dists = rbind(dists_cntrl, dists_exp)
dists$Group = rep(c('Control', exp_group), each = nrow(dists)/2)
dists$Sign = factor(ifelse(dists$weight > 0, 'Positive', 'Negative'),
                    levels = c('Positive', 'Negative'))
dists$Group = factor(dists$Group, levels = c('Control', exp_group))

# Positive networks
dists_pos = dists[dists$Sign == 'Positive',]

# Plot all correlations over distance
ggplot(data = dists_pos, aes(x = distance, y = weight, colour = Group))+
  geom_point(alpha = 0.3)+
  geom_smooth(lwd = 1.1)+
  scale_color_manual(values = c('blue', 'red'))+
  labs(x = 'Geodesic distance on the spherical cortical surface',
       y = 'Partial correlation',
       title = 'Weight as a function of cortical distance; Positive')+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 10, colour = 'black'),,
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'top',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0))
  )

# Fit GAMs and compare - per-group smoothing and no per-group smoothing
gam_model_pos = gam(weight ~ s(distance, by = Group, k = 5) + Group, 
                    data = dists_pos, family = 'gaussian')
print(summary(gam_model_pos))  # for signifiance of model terms
gam_model_pos_no_int = gam(weight ~ s(distance, k = 5) + Group, 
                       data = dists_pos, family = 'gaussian') 
dev_test = anova.gam(gam_model_pos, gam_model_pos_no_int, 
          test = 'Chisq')
print(dev_test)

# Predict weight-distance relationship from fitted GAM
distance_grid = seq(min(dists_pos$distance), 
                    max(dists_pos$distance), 
                    length.out = 100)
GAM_data = expand.grid(
  distance = seq(min(dists_pos$distance), 
                 max(dists_pos$distance), 
                 length.out = 100),
  Group = c('Control', exp_group)
)
weight_pred = predict(gam_model_pos, newdata = GAM_data, se.fit = TRUE)
GAM_data$weight = weight_pred$fit
GAM_data$se = weight_pred$se.fit

GAM_control = GAM_data[GAM_data$Group == 'Control',]
GAM_exp = GAM_data[GAM_data$Group == exp_group,]
GAM_CIs = data.frame(distance =
                       unique(GAM_data$distance),
                     diff = 
                       GAM_control$weight - GAM_exp$weight,
                     se_diff = 
                       sqrt(GAM_control$se^2 + GAM_exp$se^2))
GAM_CIs$CI_upper = GAM_CIs$diff + 1.96 * GAM_CIs$se_diff
GAM_CIs$CI_lower = GAM_CIs$diff - 1.96 * GAM_CIs$se_diff

GAM_CIs$p_value = with(GAM_CIs, 2 * pnorm(-abs(diff / se_diff)))
GAM_CIs$signif = GAM_CIs$p_value < .05


# Plot predicted curves
ggplot(GAM_data, aes(x = distance, y = weight, color = Group)) +
  geom_ribbon(aes(ymin = weight-se, ymax = weight+se, group = Group),
              fill = 'grey', colour = NA)+
  geom_line(size = 1.2) +
  annotate('text', x = 210, y = 0.28, 
           label = substitute(P[smooth] == pval, 
                              list(pval = round(dev_test[2,5], 3))),
           size = 5, hjust = 'left')+
  
  scale_color_manual(values = c("blue", "red"))+
  
  labs(title = "Predicted GAM curves; Positive", 
       x = 'Geodesic distance on the spherical cortical surface',
       y = "Predicted partial correlation") +
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 10, colour = 'black'),,
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'top',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0))
  )

# Plot GAM-predicted group differences
ggplot(GAM_CIs, aes(x = distance, y = diff)) +
  geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper),
              fill = 'grey')+
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  geom_line(color = "darkgreen", size = 1.2) +
  labs(title = "Group difference in GAM curves; Positive", 
     x = 'Geodesic distance on the spherical cortical surface',
     y = paste0("Control - ", exp_group))+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 10, colour = 'black'),,
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'none',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0))
  )

# Plot derivatives - how is weight changing
gam_deriv = derivatives(gam_model, term = "s(distance)", partial_match = T)
draw(deriv)
```

In examining the curves for positive correlations, there appears to be a difference between control and synaesthete correlations specifically at longer distances. The GAM model would suggest that these long-distance positive correlations are significantly different between groups.

```{r weight_distance_split_neg}
# Visualise weight-distance relationships for negative split networks #

# Positive networks
dists_neg = dists[dists$Sign == 'Negative',]

# Plot all correlations
ggplot(data = dists_neg, aes(x = distance, y = weight, colour = Group))+
  geom_smooth(lwd = 1.1)+
  geom_point(alpha = 0.3)+
  scale_color_manual(values = c('blue', 'red'))+
  labs(x = 'Geodesic distance on the spherical cortical surface',
       y = 'Partial correlation',
       title = 'Weight as a function of cortical distance')+
  theme_classic()+
  theme(
    text = element_text(size = 12, face = 'bold', colour = 'black'),
    axis.text = element_text(size = 10, colour = 'black'),,
    axis.line = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks = element_line(linewidth = 0.8, colour = 'black'),
    axis.ticks.length = unit(1, 'mm'),
    legend.position = 'top',
    plot.title = element_text(vjust = 2, margin = margin(0, 0, 0, 0))
  )

# Fit GAM
gam_model_neg = gam(weight ~ s(distance, by = Group, k = 5) + Group, 
                    data = dists_neg, family = 'gaussian')
print(summary(gam_model_neg))  # for signifiance of model terms
```

For negative correlations, there appears to be no clear relationship between distance and weight for controls or synaesthetes. Indeed, the GAM model indicates that the smoothing terms are not significant, suggesting that the relationship is not well described by a smooth curve. However, the parametric coefficient for group is still significant, suggesting that synaesthetes still have substantially stronger negative partial correlations compared to controls. 


## Graph complexity

An interesting line of questioning is to ask how complex the structural organisation of the brain is within different groups. A way of conceptualising complexity is about how many different patterns are represented in the organisation. If there are few unique patterns, complexity is low; if there are many, it is high. 

Complexity of signals often consists of looking at different patterns over time. However, since we are looking at static graphs, we will examine complexity of the connection topology at each node, then average this for the entire network. In our case, we are also looking at weighted, fully-connected graphs. This means complexity also cannot be evaluated based on numbers of connections, at least without arbitrary thresholding. To overcome this, we can ask how similar is the connection topology between nodes. 

The below function calculates the Jensen-Shannon divergence for the distributions of edge weights (partial correlations) for each pair of nodes, averaging it over each node as well as over the whole network. This measure gives an idea of how similar the edge weight distributions are from node to node. If JS divergence is low, this means edge distributions are similar between nodes and complexity could be considered to be low, and vice versa. Let's calculate the mean JS divergences for controls and synesthetes using the matched clustered data:

```{r js_complexity}
# Get JS complexity for controls and synesthetes
js_complexity_control = js_complexity(data_matched_wrd[[1]], 'Control')
js_complexity_exp = js_complexity(data_matched_wrd[[2]], exp_group)
print(js_complexity_control$total_js)
print(js_complexity_exp$total_js)

# Test differences by comparing mean node divergences
shapiro.test(js_complexity_control$vertex_means)
shapiro.test(js_complexity_exp$vertex_means)
t.test(js_complexity_control$vertex_means, js_complexity_exp$vertex_means)
cohens_d(js_complexity_control$vertex_means, js_complexity_exp$vertex_means)

# Get differences in vertex complexity
js_complexity_diffs = js_complexity_control$vertex_means - js_complexity_exp$vertex_means
print(js_complexity_diffs)
print(order(abs(js_complexity_diffs), decreasing = TRUE))
```

Here we see that despite a wider distribution of partial correlations, complexity is significantly lower in the synesthete network, suggesting that nodes are more similar in their distributions of connections. This could indicate reduced regional specialisation in synesthetes, as regions are less specific and unique in their connections. When looking at specific nodes, we see that regions at the parietal cortex (PGi and PGs) have a much reduced complexity in synesthetes, while areas in the frontal cortex (area 8 and 9) show very little difference in complexity. 

It is important to check to what degree this complexity measure captures randomness in graph structure. If randomness of connection strength is high, then one may expect a strong divergence between nodes. Let's calculate the complexity of graphs that have been randomly shuffled for their edge weights:

```{r js_complexity_random}
# Get JS complexity for randomised graphs
js_complexity_control_rand = js_complexity(data_matched_wrd[[1]], 
                                           'Control', randomise = T)
js_complexity_exp_rand = js_complexity(data_matched_wrd[[2]], 
                                       exp_group, randomise = T)
print(js_complexity_control_rand$total_js)
print(js_complexity_exp_rand$total_js)

# Test differences
shapiro.test(js_complexity_control_rand$vertex_means)
shapiro.test(js_complexity_exp_rand$vertex_means)
t.test(js_complexity_control_rand$vertex_means, js_complexity_exp_rand$vertex_means)
cohens_d(js_complexity_control_rand$vertex_means, js_complexity_exp_rand$vertex_means)

```

Indeed, we see that for both the control and synesthete networks, the mean divergence is greater when the networks are randomly shuffled. This means that the measure may be capturing randomness in the structure of the networks. Interestingly, randomisation does not make the complexity larger in the synesthete network compared to the unrandomised control network, suggesting that the graph-wide distribution of connection weights plays a larger role in shaping the average divergence than the network topology. Nonetheless, we do now find reduced evidence for a difference between network complexity when the graphs are randomised, showing that topology is important for group differences in complexity. 
